{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Q2 Weather Recognition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99e5495cfd0377aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dependencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca55320b036ae577"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-14T16:10:00.728826200Z"
    }
   },
   "id": "bf8eef0aaad5b68"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construct Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47847931ae3de93c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "# Get the path of all JPG files in the folder\n",
    "folder_path = '../Q2_data/train_data'\n",
    "file_list = os.listdir(folder_path)\n",
    "jpg_files = [file for file in file_list if file.endswith('.jpg')]\n",
    "print(len(jpg_files))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:10:11.821977900Z",
     "start_time": "2023-12-14T16:10:11.804467Z"
    }
   },
   "id": "eba4bcd86a2b10b5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define a global transformer to appropriately scale images and subsequently convert them to a Tensor\n",
    "img_size = 224\n",
    "loader = transforms.Compose([\n",
    "  transforms.Resize(img_size),\n",
    "  transforms.CenterCrop(img_size),\n",
    "  transforms.ToTensor(),\n",
    "])\n",
    "def load_image(filename):\n",
    "    image = PILImage.open(filename).convert('RGB')\n",
    "    image_tensor = loader(image).float()\n",
    "    image_var = Variable(image_tensor).unsqueeze(0)\n",
    "    return image_var"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:10:17.296776100Z",
     "start_time": "2023-12-14T16:10:17.291777700Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Convert the images in the folder to a tensor of 3 * 224 * 224\n",
    "images_list = [load_image(folder_path+'/'+file) for file in jpg_files]\n",
    "all_img = torch.cat(images_list, dim=0)\n",
    "print(all_img.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:10:21.662718600Z",
     "start_time": "2023-12-14T16:10:19.378656400Z"
    }
   },
   "id": "790d4b5f24402c74"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 5])\n"
     ]
    }
   ],
   "source": [
    "# Convert weather labels into the form of one-hot encoding\n",
    "label_list = []\n",
    "weather_list = ['Cloudy', 'Foggy', 'Rainy', 'Snowy', 'Sunny']\n",
    "for file in jpg_files:\n",
    "    label = []\n",
    "    for weather in weather_list:\n",
    "        if weather in file:\n",
    "           label.append(1) \n",
    "        else:\n",
    "            label.append(0)\n",
    "    label_list.append(label)\n",
    "    \n",
    "all_labels = torch.Tensor(label_list)\n",
    "print(all_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:10:23.985198300Z",
     "start_time": "2023-12-14T16:10:23.969198500Z"
    }
   },
   "id": "7c37c6c6b90fc976"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb7c99837a3d9f8e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Construct a class for the model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "\n",
    "            )\n",
    "\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.Linear(1000, 5),\n",
    "\n",
    "            )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        # x = self.sigmoid(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:59.313987300Z",
     "start_time": "2023-12-14T16:19:59.294988200Z"
    }
   },
   "id": "9b88454dc1f9f902"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [5], Loss: 2.5191080570220947\n",
      "Epoch [1/100], Step [10], Loss: 3.668705463409424\n",
      "Epoch [2/100], Step [5], Loss: 1.542222261428833\n",
      "Epoch [2/100], Step [10], Loss: 1.3412532806396484\n",
      "Epoch [3/100], Step [5], Loss: 1.4309747219085693\n",
      "Epoch [3/100], Step [10], Loss: 1.49448823928833\n",
      "Epoch [4/100], Step [5], Loss: 1.250004768371582\n",
      "Epoch [4/100], Step [10], Loss: 1.3834022283554077\n",
      "Epoch [5/100], Step [5], Loss: 1.4812248945236206\n",
      "Epoch [5/100], Step [10], Loss: 1.3480709791183472\n",
      "Epoch [6/100], Step [5], Loss: 1.3229665756225586\n",
      "Epoch [6/100], Step [10], Loss: 1.2914235591888428\n",
      "Epoch [7/100], Step [5], Loss: 1.5125315189361572\n",
      "Epoch [7/100], Step [10], Loss: 1.394298791885376\n",
      "Epoch [8/100], Step [5], Loss: 1.328277587890625\n",
      "Epoch [8/100], Step [10], Loss: 1.6516457796096802\n",
      "Epoch [9/100], Step [5], Loss: 1.4532438516616821\n",
      "Epoch [9/100], Step [10], Loss: 1.2924716472625732\n",
      "Epoch [10/100], Step [5], Loss: 1.502036213874817\n",
      "Epoch [10/100], Step [10], Loss: 1.3767292499542236\n",
      "Epoch [11/100], Step [5], Loss: 1.4203875064849854\n",
      "Epoch [11/100], Step [10], Loss: 1.4886225461959839\n",
      "Epoch [12/100], Step [5], Loss: 1.4344537258148193\n",
      "Epoch [12/100], Step [10], Loss: 1.3338820934295654\n",
      "Epoch [13/100], Step [5], Loss: 1.2577018737792969\n",
      "Epoch [13/100], Step [10], Loss: 1.2424371242523193\n",
      "Epoch [14/100], Step [5], Loss: 1.428531289100647\n",
      "Epoch [14/100], Step [10], Loss: 1.1703264713287354\n",
      "Epoch [15/100], Step [5], Loss: 1.7393537759780884\n",
      "Epoch [15/100], Step [10], Loss: 1.3307914733886719\n",
      "Epoch [16/100], Step [5], Loss: 1.306679368019104\n",
      "Epoch [16/100], Step [10], Loss: 1.3977080583572388\n",
      "Epoch [17/100], Step [5], Loss: 1.3648165464401245\n",
      "Epoch [17/100], Step [10], Loss: 1.3948489427566528\n",
      "Epoch [18/100], Step [5], Loss: 1.3117705583572388\n",
      "Epoch [18/100], Step [10], Loss: 1.2863006591796875\n",
      "Epoch [19/100], Step [5], Loss: 1.241988182067871\n",
      "Epoch [19/100], Step [10], Loss: 1.2345634698867798\n",
      "Epoch [20/100], Step [5], Loss: 1.1669507026672363\n",
      "Epoch [20/100], Step [10], Loss: 1.373240351676941\n",
      "Epoch [21/100], Step [5], Loss: 1.1494628190994263\n",
      "Epoch [21/100], Step [10], Loss: 1.185638427734375\n",
      "Epoch [22/100], Step [5], Loss: 1.0834896564483643\n",
      "Epoch [22/100], Step [10], Loss: 1.1873204708099365\n",
      "Epoch [23/100], Step [5], Loss: 0.891559898853302\n",
      "Epoch [23/100], Step [10], Loss: 0.996918797492981\n",
      "Epoch [24/100], Step [5], Loss: 0.9717730283737183\n",
      "Epoch [24/100], Step [10], Loss: 0.9189579486846924\n",
      "Epoch [25/100], Step [5], Loss: 0.8826025128364563\n",
      "Epoch [25/100], Step [10], Loss: 1.159373164176941\n",
      "Epoch [26/100], Step [5], Loss: 0.8980646133422852\n",
      "Epoch [26/100], Step [10], Loss: 0.7700798511505127\n",
      "Epoch [27/100], Step [5], Loss: 0.9747835993766785\n",
      "Epoch [27/100], Step [10], Loss: 1.0007288455963135\n",
      "Epoch [28/100], Step [5], Loss: 0.8847777247428894\n",
      "Epoch [28/100], Step [10], Loss: 0.9183195233345032\n",
      "Epoch [29/100], Step [5], Loss: 1.186424732208252\n",
      "Epoch [29/100], Step [10], Loss: 1.0017789602279663\n",
      "Epoch [30/100], Step [5], Loss: 0.9067679643630981\n",
      "Epoch [30/100], Step [10], Loss: 0.5690378546714783\n",
      "Epoch [31/100], Step [5], Loss: 0.9760998487472534\n",
      "Epoch [31/100], Step [10], Loss: 1.0913445949554443\n",
      "Epoch [32/100], Step [5], Loss: 0.7379726767539978\n",
      "Epoch [32/100], Step [10], Loss: 1.0025279521942139\n",
      "Epoch [33/100], Step [5], Loss: 1.4913979768753052\n",
      "Epoch [33/100], Step [10], Loss: 0.5866880416870117\n",
      "Epoch [34/100], Step [5], Loss: 0.6306329369544983\n",
      "Epoch [34/100], Step [10], Loss: 0.5613647103309631\n",
      "Epoch [35/100], Step [5], Loss: 0.6502634286880493\n",
      "Epoch [35/100], Step [10], Loss: 1.4041355848312378\n",
      "Epoch [36/100], Step [5], Loss: 0.3736811876296997\n",
      "Epoch [36/100], Step [10], Loss: 0.5848550200462341\n",
      "Epoch [37/100], Step [5], Loss: 0.363253116607666\n",
      "Epoch [37/100], Step [10], Loss: 0.5557248592376709\n",
      "Epoch [38/100], Step [5], Loss: 0.4831122159957886\n",
      "Epoch [38/100], Step [10], Loss: 0.28872814774513245\n",
      "Epoch [39/100], Step [5], Loss: 0.9379774332046509\n",
      "Epoch [39/100], Step [10], Loss: 0.5409938097000122\n",
      "Epoch [40/100], Step [5], Loss: 0.8999159932136536\n",
      "Epoch [40/100], Step [10], Loss: 0.41800230741500854\n",
      "Epoch [41/100], Step [5], Loss: 0.634990930557251\n",
      "Epoch [41/100], Step [10], Loss: 0.34789320826530457\n",
      "Epoch [42/100], Step [5], Loss: 0.3996116518974304\n",
      "Epoch [42/100], Step [10], Loss: 0.5824852585792542\n",
      "Epoch [43/100], Step [5], Loss: 0.3470079004764557\n",
      "Epoch [43/100], Step [10], Loss: 0.953497588634491\n",
      "Epoch [44/100], Step [5], Loss: 0.5491944551467896\n",
      "Epoch [44/100], Step [10], Loss: 0.5412826538085938\n",
      "Epoch [45/100], Step [5], Loss: 0.39486661553382874\n",
      "Epoch [45/100], Step [10], Loss: 0.6257030963897705\n",
      "Epoch [46/100], Step [5], Loss: 0.45247548818588257\n",
      "Epoch [46/100], Step [10], Loss: 0.4662168025970459\n",
      "Epoch [47/100], Step [5], Loss: 0.16489277780056\n",
      "Epoch [47/100], Step [10], Loss: 0.41850805282592773\n",
      "Epoch [48/100], Step [5], Loss: 0.4141351282596588\n",
      "Epoch [48/100], Step [10], Loss: 0.4773135185241699\n",
      "Epoch [49/100], Step [5], Loss: 0.6986268162727356\n",
      "Epoch [49/100], Step [10], Loss: 0.9034206867218018\n",
      "Epoch [50/100], Step [5], Loss: 0.29807209968566895\n",
      "Epoch [50/100], Step [10], Loss: 0.7304771542549133\n",
      "Epoch [51/100], Step [5], Loss: 0.5877366662025452\n",
      "Epoch [51/100], Step [10], Loss: 0.510506808757782\n",
      "Epoch [52/100], Step [5], Loss: 0.42887693643569946\n",
      "Epoch [52/100], Step [10], Loss: 0.6338071227073669\n",
      "Epoch [53/100], Step [5], Loss: 0.297606498003006\n",
      "Epoch [53/100], Step [10], Loss: 0.33158940076828003\n",
      "Epoch [54/100], Step [5], Loss: 0.24632617831230164\n",
      "Epoch [54/100], Step [10], Loss: 0.23048315942287445\n",
      "Epoch [55/100], Step [5], Loss: 0.39573103189468384\n",
      "Epoch [55/100], Step [10], Loss: 0.8372749090194702\n",
      "Epoch [56/100], Step [5], Loss: 0.39225101470947266\n",
      "Epoch [56/100], Step [10], Loss: 0.3232457935810089\n",
      "Epoch [57/100], Step [5], Loss: 0.14785273373126984\n",
      "Epoch [57/100], Step [10], Loss: 0.4400482177734375\n",
      "Epoch [58/100], Step [5], Loss: 0.32027897238731384\n",
      "Epoch [58/100], Step [10], Loss: 0.3787280321121216\n",
      "Epoch [59/100], Step [5], Loss: 0.3582407236099243\n",
      "Epoch [59/100], Step [10], Loss: 0.4826558530330658\n",
      "Epoch [60/100], Step [5], Loss: 0.2765176296234131\n",
      "Epoch [60/100], Step [10], Loss: 0.5039196014404297\n",
      "Epoch [61/100], Step [5], Loss: 0.2879579961299896\n",
      "Epoch [61/100], Step [10], Loss: 0.22562575340270996\n",
      "Epoch [62/100], Step [5], Loss: 0.15864747762680054\n",
      "Epoch [62/100], Step [10], Loss: 0.5960984826087952\n",
      "Epoch [63/100], Step [5], Loss: 0.16102349758148193\n",
      "Epoch [63/100], Step [10], Loss: 0.3910633325576782\n",
      "Epoch [64/100], Step [5], Loss: 0.10116121172904968\n",
      "Epoch [64/100], Step [10], Loss: 0.30215537548065186\n",
      "Epoch [65/100], Step [5], Loss: 0.31651031970977783\n",
      "Epoch [65/100], Step [10], Loss: 0.6192139387130737\n",
      "Epoch [66/100], Step [5], Loss: 0.30019062757492065\n",
      "Epoch [66/100], Step [10], Loss: 0.6354753971099854\n",
      "Epoch [67/100], Step [5], Loss: 0.3512199819087982\n",
      "Epoch [67/100], Step [10], Loss: 0.44344016909599304\n",
      "Epoch [68/100], Step [5], Loss: 0.13486704230308533\n",
      "Epoch [68/100], Step [10], Loss: 0.2652905583381653\n",
      "Epoch [69/100], Step [5], Loss: 0.4468390643596649\n",
      "Epoch [69/100], Step [10], Loss: 0.19343283772468567\n",
      "Epoch [70/100], Step [5], Loss: 0.282917320728302\n",
      "Epoch [70/100], Step [10], Loss: 0.09817531704902649\n",
      "Epoch [71/100], Step [5], Loss: 0.15387269854545593\n",
      "Epoch [71/100], Step [10], Loss: 0.21717987954616547\n",
      "Epoch [72/100], Step [5], Loss: 0.2324029505252838\n",
      "Epoch [72/100], Step [10], Loss: 0.0899566039443016\n",
      "Epoch [73/100], Step [5], Loss: 0.33712828159332275\n",
      "Epoch [73/100], Step [10], Loss: 0.3245261013507843\n",
      "Epoch [74/100], Step [5], Loss: 0.17130595445632935\n",
      "Epoch [74/100], Step [10], Loss: 0.4314808249473572\n",
      "Epoch [75/100], Step [5], Loss: 0.3788694739341736\n",
      "Epoch [75/100], Step [10], Loss: 0.29278889298439026\n",
      "Epoch [76/100], Step [5], Loss: 0.12931805849075317\n",
      "Epoch [76/100], Step [10], Loss: 0.22338421642780304\n",
      "Epoch [77/100], Step [5], Loss: 0.22098925709724426\n",
      "Epoch [77/100], Step [10], Loss: 0.28906145691871643\n",
      "Epoch [78/100], Step [5], Loss: 0.24820075929164886\n",
      "Epoch [78/100], Step [10], Loss: 0.9600489735603333\n",
      "Epoch [79/100], Step [5], Loss: 0.289728045463562\n",
      "Epoch [79/100], Step [10], Loss: 0.5887829661369324\n",
      "Epoch [80/100], Step [5], Loss: 0.22490599751472473\n",
      "Epoch [80/100], Step [10], Loss: 0.3190971612930298\n",
      "Epoch [81/100], Step [5], Loss: 0.12291619181632996\n",
      "Epoch [81/100], Step [10], Loss: 0.2754388451576233\n",
      "Epoch [82/100], Step [5], Loss: 0.0650470033288002\n",
      "Epoch [84/100], Step [5], Loss: 0.16056765615940094\n",
      "Epoch [84/100], Step [10], Loss: 1.310774803161621\n",
      "Epoch [85/100], Step [5], Loss: 0.5957211256027222\n",
      "Epoch [85/100], Step [10], Loss: 0.249471053481102\n",
      "Epoch [86/100], Step [5], Loss: 0.5638387799263\n",
      "Epoch [86/100], Step [10], Loss: 0.10855824500322342\n",
      "Epoch [87/100], Step [5], Loss: 0.15598681569099426\n",
      "Epoch [87/100], Step [10], Loss: 0.1709413081407547\n",
      "Epoch [89/100], Step [5], Loss: 0.07124853879213333\n",
      "Epoch [89/100], Step [10], Loss: 0.2657475173473358\n",
      "Epoch [91/100], Step [5], Loss: 0.14295247197151184\n",
      "Epoch [91/100], Step [10], Loss: 0.1029873937368393\n",
      "Epoch [92/100], Step [5], Loss: 0.18518413603305817\n",
      "Epoch [92/100], Step [10], Loss: 0.7035905122756958\n",
      "Epoch [93/100], Step [5], Loss: 0.08055080473423004\n",
      "Epoch [93/100], Step [10], Loss: 0.4536517858505249\n",
      "Epoch [96/100], Step [5], Loss: 0.08902082592248917\n",
      "Epoch [96/100], Step [10], Loss: 0.11713296920061111\n",
      "Epoch [97/100], Step [5], Loss: 0.3128395676612854\n",
      "Epoch [99/100], Step [5], Loss: 0.04520934075117111\n",
      "Epoch [100/100], Step [5], Loss: 0.07075919210910797\n",
      "Epoch [100/100], Step [10], Loss: 0.10086689889431\n"
     ]
    }
   ],
   "source": [
    "# Send model into GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNModel().to(device)\n",
    "\n",
    "# Define a training function\n",
    "def train(model, learning_rate=0.0005, batch_size=25, epochs=100):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Encapsulate the data\n",
    "    train_dataset = TensorDataset(all_img, all_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "\n",
    "            loss = criterion(outputs, labels.float()).to(device)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 5 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{epochs}], Step [{i + 1}], Loss: {loss.item()}')\n",
    "\n",
    "# Finally train the model\n",
    "train(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:26:44.690700500Z",
     "start_time": "2023-12-14T16:23:49.859758400Z"
    }
   },
   "id": "29ed86268fa25c78"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41e78bef90636070"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 96.40 %\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    train_dataset = TensorDataset(all_img, all_labels)\n",
    "    train_loader = DataLoader(train_dataset)\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs = inputs.double()\n",
    "        outputs = model(inputs.float())\n",
    "        predicted = torch.max(outputs, 1)[1]\n",
    "        label = torch.max(labels, 1)[1]\n",
    "        correct += (predicted == label).sum()\n",
    "\n",
    "# Calculate the accuracy \n",
    "print('acc: %.2f %%' % (100 * correct / 250))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:26:49.005882700Z",
     "start_time": "2023-12-14T16:26:47.966840500Z"
    }
   },
   "id": "5096758ad35fca25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
